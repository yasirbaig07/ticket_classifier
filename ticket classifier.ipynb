{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d942f3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install transformers datasets torch scikit-learn pandas numpy matplotlib seaborn sentence-transformers\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import random\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "def generate_simple_tickets(n_samples=200):\n",
    "    categories = ['Technical', 'Billing', 'Account', 'Feature Request', 'Bug Report', 'Login']\n",
    "\n",
    "    templates = {\n",
    "        'Technical': [\"System not working\", \"Technical error occurred\", \"Can't access features\"],\n",
    "        'Billing': [\"Wrong charge amount\", \"Billing question\", \"Payment failed\"],\n",
    "        'Account': [\"Update profile\", \"Change settings\", \"Account locked\"],\n",
    "        'Feature Request': [\"Add new feature\", \"Improve functionality\", \"Need better tools\"],\n",
    "        'Bug Report': [\"Found a bug\", \"Error in system\", \"Something broken\"],\n",
    "        'Login': [\"Can't login\", \"Password reset\", \"Login failed\"]\n",
    "    }\n",
    "\n",
    "    tickets = []\n",
    "    for _ in range(n_samples):\n",
    "        category = random.choice(categories)\n",
    "        base_text = random.choice(templates[category])\n",
    "        variations = [\n",
    "            f\"{base_text} in the application\",\n",
    "            f\"Help with {base_text.lower()}\",\n",
    "            f\"Issue: {base_text.lower()}\",\n",
    "            f\"Problem with {base_text.lower()}\",\n",
    "            base_text\n",
    "        ]\n",
    "        ticket_text = random.choice(variations)\n",
    "        tickets.append({'text': ticket_text, 'category': category})\n",
    "\n",
    "    return pd.DataFrame(tickets)\n",
    "\n",
    "print(\"Generating small dataset...\")\n",
    "df = generate_simple_tickets(200)\n",
    "print(\"Dataset created!\")\n",
    "print(\"\\nCategory Distribution:\")\n",
    "print(df['category'].value_counts())\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['category'])\n",
    "num_labels = len(label_encoder.classes_)\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    df['text'], df['label'], test_size=0.4, random_state=42, stratify=df['label']\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "train_df = pd.DataFrame({'text': X_train, 'label': y_train})\n",
    "val_df = pd.DataFrame({'text': X_val, 'label': y_val})\n",
    "test_df = pd.DataFrame({'text': X_test, 'label': y_test})\n",
    "\n",
    "print(f\"Train: {len(train_df)}, Val: {len(val_df)}, Test: {len(test_df)}\")\n",
    "\n",
    "class FastZeroShotClassifier:\n",
    "    def __init__(self):\n",
    "        print(\"Loading lightweight sentence transformer...\")\n",
    "        self.model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        self.categories = label_encoder.classes_.tolist()\n",
    "        self.category_embeddings = self.model.encode(self.categories)\n",
    "\n",
    "    def predict(self, texts, top_k=3):\n",
    "        if isinstance(texts, str):\n",
    "            texts = [texts]\n",
    "\n",
    "        text_embeddings = self.model.encode(texts)\n",
    "        similarities = cosine_similarity(text_embeddings, self.category_embeddings)\n",
    "\n",
    "        predictions = []\n",
    "        for sim_scores in similarities:\n",
    "            top_indices = np.argsort(sim_scores)[::-1][:top_k]\n",
    "            top_predictions = [(self.categories[idx], sim_scores[idx]) for idx in top_indices]\n",
    "            predictions.append(top_predictions)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def predict_single_label(self, texts):\n",
    "        predictions = self.predict(texts, top_k=1)\n",
    "        single_preds = []\n",
    "        for pred in predictions:\n",
    "            label_name = pred[0][0]\n",
    "            label_idx = label_encoder.transform([label_name])[0]\n",
    "            single_preds.append(label_idx)\n",
    "        return single_preds\n",
    "\n",
    "class FastFewShotClassifier:\n",
    "    def __init__(self):\n",
    "        print(\"Loading few-shot classifier...\")\n",
    "        self.model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        self.categories = label_encoder.classes_.tolist()\n",
    "        self.examples = self._create_examples()\n",
    "\n",
    "    def _create_examples(self):\n",
    "        examples = {}\n",
    "        for category in self.categories:\n",
    "            category_samples = train_df[train_df['label'] == label_encoder.transform([category])[0]]\n",
    "            if len(category_samples) > 0:\n",
    "                examples[category] = category_samples['text'].iloc[0]\n",
    "            else:\n",
    "                examples[category] = f\"Sample {category.lower()} ticket\"\n",
    "        return examples\n",
    "\n",
    "    def predict(self, texts, top_k=3):\n",
    "        if isinstance(texts, str):\n",
    "            texts = [texts]\n",
    "\n",
    "        enhanced_categories = []\n",
    "        for cat in self.categories:\n",
    "            enhanced_cat = f\"{cat}: {self.examples[cat]}\"\n",
    "            enhanced_categories.append(enhanced_cat)\n",
    "\n",
    "        text_embeddings = self.model.encode(texts)\n",
    "        category_embeddings = self.model.encode(enhanced_categories)\n",
    "        similarities = cosine_similarity(text_embeddings, category_embeddings)\n",
    "\n",
    "        predictions = []\n",
    "        for sim_scores in similarities:\n",
    "            top_indices = np.argsort(sim_scores)[::-1][:top_k]\n",
    "            top_predictions = [(self.categories[idx], sim_scores[idx]) for idx in top_indices]\n",
    "            predictions.append(top_predictions)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def predict_single_label(self, texts):\n",
    "        predictions = self.predict(texts, top_k=1)\n",
    "        single_preds = []\n",
    "        for pred in predictions:\n",
    "            label_name = pred[0][0]\n",
    "            label_idx = label_encoder.transform([label_name])[0]\n",
    "            single_preds.append(label_idx)\n",
    "        return single_preds\n",
    "\n",
    "class FastFineTunedClassifier:\n",
    "    def __init__(self, model_name=\"distilbert-base-uncased\"):\n",
    "        self.model_name = model_name\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = None\n",
    "\n",
    "    def preprocess_data(self, texts, labels=None):\n",
    "        encodings = self.tokenizer(\n",
    "            texts.tolist() if hasattr(texts, 'tolist') else list(texts),\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=128,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        if labels is not None:\n",
    "            encodings['labels'] = torch.tensor(labels.tolist() if hasattr(labels, 'tolist') else list(labels))\n",
    "\n",
    "        return Dataset.from_dict(encodings)\n",
    "\n",
    "    def train(self, train_texts, train_labels, val_texts, val_labels):\n",
    "        print(\"Loading model for fine-tuning...\")\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            self.model_name,\n",
    "            num_labels=num_labels\n",
    "        )\n",
    "\n",
    "        train_dataset = self.preprocess_data(train_texts, train_labels)\n",
    "        val_dataset = self.preprocess_data(val_texts, val_labels)\n",
    "\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir='./results',\n",
    "            num_train_epochs=1,\n",
    "            per_device_train_batch_size=16,\n",
    "            per_device_eval_batch_size=32,\n",
    "            warmup_steps=50,\n",
    "            weight_decay=0.01,\n",
    "            logging_dir='./logs',\n",
    "            evaluation_strategy=\"no\",\n",
    "            save_strategy=\"no\",\n",
    "            logging_steps=20,\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=self.model,\n",
    "            args=training_args,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=val_dataset,\n",
    "        )\n",
    "\n",
    "        print(\"Training model...\")\n",
    "        trainer.train()\n",
    "        self.model = trainer.model\n",
    "\n",
    "    def predict(self, texts, top_k=3):\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model not trained yet\")\n",
    "\n",
    "        inputs = self.tokenizer(\n",
    "            texts.tolist() if hasattr(texts, 'tolist') else list(texts),\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=128,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "            predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "\n",
    "        results = []\n",
    "        for pred in predictions:\n",
    "            top_indices = torch.topk(pred, top_k).indices\n",
    "            top_scores = torch.topk(pred, top_k).values\n",
    "\n",
    "            top_predictions = []\n",
    "            for idx, score in zip(top_indices, top_scores):\n",
    "                label = label_encoder.inverse_transform([idx.item()])[0]\n",
    "                top_predictions.append((label, score.item()))\n",
    "\n",
    "            results.append(top_predictions)\n",
    "\n",
    "        return results\n",
    "\n",
    "    def predict_single_label(self, texts):\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model not trained yet\")\n",
    "\n",
    "        inputs = self.tokenizer(\n",
    "            texts.tolist() if hasattr(texts, 'tolist') else list(texts),\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=128,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "            predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "\n",
    "        return predictions.tolist()\n",
    "\n",
    "def evaluate_classifier(classifier, test_texts, test_labels, classifier_name):\n",
    "    print(f\"\\n{classifier_name} Evaluation:\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "    y_pred = classifier.predict_single_label(test_texts)\n",
    "\n",
    "    accuracy = accuracy_score(test_labels, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    return accuracy, y_pred\n",
    "\n",
    "def evaluate_top_k_predictions(classifier, test_texts, test_labels, classifier_name, k=3):\n",
    "    print(f\"\\n{classifier_name} Top-{k} Predictions:\")\n",
    "\n",
    "    predictions = classifier.predict(test_texts, top_k=k)\n",
    "\n",
    "    for i in range(1, k+1):\n",
    "        correct = 0\n",
    "        for pred_list, true_label in zip(predictions, test_labels):\n",
    "            true_label_name = label_encoder.inverse_transform([true_label])[0]\n",
    "            top_i_labels = [pred[0] for pred in pred_list[:i]]\n",
    "            if true_label_name in top_i_labels:\n",
    "                correct += 1\n",
    "\n",
    "        accuracy = correct / len(test_labels)\n",
    "        print(f\"Top-{i} Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FAST EVALUATION STARTING\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\nInitializing Zero-Shot Classifier...\")\n",
    "zero_shot = FastZeroShotClassifier()\n",
    "\n",
    "print(\"Evaluating Zero-Shot...\")\n",
    "zero_shot_acc, zero_shot_pred = evaluate_classifier(zero_shot, X_test, y_test, \"Zero-Shot\")\n",
    "evaluate_top_k_predictions(zero_shot, X_test, y_test, \"Zero-Shot\", k=3)\n",
    "\n",
    "print(\"\\nInitializing Few-Shot Classifier...\")\n",
    "few_shot = FastFewShotClassifier()\n",
    "\n",
    "print(\"Evaluating Few-Shot...\")\n",
    "few_shot_acc, few_shot_pred = evaluate_classifier(few_shot, X_test, y_test, \"Few-Shot\")\n",
    "evaluate_top_k_predictions(few_shot, X_test, y_test, \"Few-Shot\", k=3)\n",
    "\n",
    "print(\"\\nTraining Fine-Tuned Classifier...\")\n",
    "fine_tuned = FastFineTunedClassifier()\n",
    "fine_tuned.train(X_train, y_train, X_val, y_val)\n",
    "\n",
    "print(\"Evaluating Fine-Tuned...\")\n",
    "fine_tuned_acc, fine_tuned_pred = evaluate_classifier(fine_tuned, X_test, y_test, \"Fine-Tuned\")\n",
    "evaluate_top_k_predictions(fine_tuned, X_test, y_test, \"Fine-Tuned\", k=3)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "accuracies = [zero_shot_acc, few_shot_acc, fine_tuned_acc]\n",
    "methods = ['Zero-Shot', 'Few-Shot', 'Fine-Tuned']\n",
    "bars = plt.bar(methods, accuracies, color=['skyblue', 'lightgreen', 'salmon'])\n",
    "plt.title('Classification Accuracy Comparison')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "             f'{acc:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "categories = label_encoder.classes_\n",
    "category_counts = [sum(y_test == i) for i in range(len(categories))]\n",
    "plt.pie(category_counts, labels=categories, autopct='%1.1f%%')\n",
    "plt.title('Test Set Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "def demonstrate_predictions(sample_texts, classifiers, classifier_names):\n",
    "    print(\"\\nSample Predictions:\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    for i, text in enumerate(sample_texts):\n",
    "        print(f\"\\nTicket {i+1}: '{text}'\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "        for classifier, name in zip(classifiers, classifier_names):\n",
    "            predictions = classifier.predict([text], top_k=3)[0]\n",
    "            print(f\"{name:12}: \", end=\"\")\n",
    "            for j, (label, score) in enumerate(predictions):\n",
    "                print(f\"{j+1}.{label}({score:.2f})\", end=\"  \")\n",
    "            print()\n",
    "\n",
    "sample_tickets = [\n",
    "    \"Can't login to my account\",\n",
    "    \"System is very slow\",\n",
    "    \"Wrong billing amount charged\",\n",
    "    \"Need new export feature\",\n",
    "    \"Found bug in dashboard\"\n",
    "]\n",
    "\n",
    "demonstrate_predictions(\n",
    "    sample_tickets,\n",
    "    [zero_shot, few_shot, fine_tuned],\n",
    "    [\"Zero-Shot\", \"Few-Shot\", \"Fine-Tuned\"]\n",
    ")\n",
    "\n",
    "results_summary = {\n",
    "    'Method': ['Zero-Shot', 'Few-Shot', 'Fine-Tuned'],\n",
    "    'Accuracy': [zero_shot_acc, few_shot_acc, fine_tuned_acc]\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results_summary)\n",
    "print(\"\\nFinal Results:\")\n",
    "print(\"=\"*30)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "print(f\"\\nBest performing method: {results_df.loc[results_df['Accuracy'].idxmax(), 'Method']}\")\n",
    "print(\"All evaluations completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
